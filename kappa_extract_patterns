#!/usr/bin/env python3

###############################################################################
#                 KEY AMINOACID PATTERN-BASED PROTEIN ANALYZER                #
#                    KAPPA 1.1 -- Pattern extraction script                   #
###############################################################################

# =============================================================================
# PLEASE CITE:
#   Joly V and Matton DP (2015). KAPPA, a simple algorithm for discovery and
#   clustering of proteins defined by a key amino acid pattern: a case study
#   of the cysteine-rich proteins. Bioinformatics, 31(11), 1716--1723.
#   DOI: 10.1093/bioinformatics/btv047
# =============================================================================
# LICENSE
#   This program is under Creative Commons BY-NC-SA 3.0 License
#   More information at: http://creativecommons.org/licenses/by-nc-sa/3.0/
# =============================================================================
# CONTACT
#   Valentin Joly, doctorant / Ph.D. student
#   Université de Montréal - Institut de Recherche en Biologie Végétale
#   4101, rue Sherbrooke Est
#   Montréal (QC) H2J 2B2
#   valentin.joly (at) umontreal.ca
# =============================================================================

import argparse
import csv
import datetime
import math
import os
import re
import sys


def print_stdout(message, level, end):
    time = datetime.datetime.now().strftime('%H:%M:%S')
    print(time, end='')
    spacer = ' ' * (level + 1) * 4
    print(spacer, end='')
    print(message)
    print(end, end='')


def import_alignment(alignment_file_name):
    alignment_file = open(alignment_file_name, 'r')
    alignment = {}

    i = -1

    fasta_structure_simple = re.compile('^>([^ ]*)[^\n]*$')
    fasta_structure_complex = re.compile('^>[^\| ]*\|([^\| ]*)[^\n]*$')

    for line in alignment_file:
        line = line.strip()

        if line != '':
            if line[0] == '>':
                fasta_ID_simple = fasta_structure_simple.match(line)
                fasta_ID_complex = fasta_structure_complex.match(line)

                if fasta_ID_complex is not None:
                    i += 1
                    seqID = fasta_ID_complex.group(1)
                    alignment[seqID] = ''

                elif fasta_structure_simple is not None:
                    i += 1
                    seqID = fasta_ID_simple.group(1)
                    alignment[seqID] = ''

                else:
                    sys.stderr.write(
                        'ERROR: Sequence file does not respect FASTA '
                        'format specifications.\n\n'
                    )
                    sys.exit(1)

            else:
                if i > -1:
                    alignment[seqID] += line.upper()

    alignment_file.close()

    nseq = len(alignment)
    if nseq == 0:
        sys.stderr.write('ERROR: No input sequence was found.\n\n')
        sys.exit(1)

    length = 0
    for sequence in alignment.values():
        if len(sequence) > length:
            length = len(sequence)
    for sequence in alignment.values():
        if len(sequence) < length:
            sys.stderr.write('ERROR: Sequences are not aligned.\n\n')
            sys.exit(1)
    if length == 0:
        sys.stderr.write('ERROR: No input sequence was found.\n\n')
        sys.exit(1)

    return alignment, nseq, length


def check_key_residues(alignment, nseq, length, key_residue, tolerance_key):

    for i in range(length):
        nkey = 0
        for sequence in alignment.values():
            if sequence[i] == key_residue:
                nkey += 1
        if nkey > 0:
            if 1.0 * nkey / nseq >= tolerance_key:
                for seqid in alignment.keys():
                    sequence = alignment[seqid]
                    if sequence[i] != 'C':
                        alignment[
                            seqid] = sequence[:i] + 'C' + sequence[i + 1:]
            else:
                for seqid in alignment.keys():
                    sequence = alignment[seqid]
                    if sequence[i] == 'C':
                        alignment[
                            seqid] = sequence[:i] + 'X' + sequence[i + 1:]

    return alignment


def extract_patterns(alignment, key_residue):

    patterns = {}

    for seqid in alignment.keys():
        sequence = alignment[seqid]
        pattern = [0]
        for aa in sequence:
            if aa == key_residue:
                pattern.append(0)
            elif aa.isalpha():
                pattern[-1] += 1
        patterns[seqid] = tuple(pattern)
        nblocks = len(pattern)

    return patterns, nblocks


def make_consensus(patterns, key_residue, nblocks, tolerance_blocks):

    consensus = []

    for i in range(nblocks):
        values = []
        for pattern in patterns.values():
            values.append(pattern[i])
        values.sort()
        if tolerance_blocks > 0:
            mini = values[math.ceil(len(values) * tolerance_blocks) - 1]
            maxi = values[math.ceil(len(values) * (1 - tolerance_blocks)) - 1]
        else:
            mini, maxi = values[0], values[-1]
        if mini == maxi:
            if mini == 0:
                position = ''
            elif mini == 1:
                position = 'X'
            elif mini == 2:
                position = 'XX'
            elif mini == 3:
                position = 'XXX'
            else:
                position = 'X{' + str(mini) + '}'
        else:
            position = 'X{' + str(mini) + '-' + str(maxi) + '}'
        consensus.append(position)

    consensus = key_residue.join(consensus)

    return consensus


if __name__ == '__main__':

    print('')
    print('*'*80)
    print('*' + ' '*20 + 'KAPPA 1.1 -- Pattern extraction script' +
          ' '*20 + '*')
    print('*'*80)
    print('')

    parser = argparse.ArgumentParser(
        description='KAPPA Pattern extraction script.', add_help=False)
    group1 = parser.add_argument_group('General parameters')
    group1.add_argument(
        '-a',
        '--alignments',
        metavar='FILE',
        nargs='+',
        required=True,
        help='FASTA file(s) containing protein sequences.')
    group1.add_argument(
        '-k',
        '--key_residue',
        metavar='AA',
        default='C',
        help='Key residue for pattern alignment.')
    group1.add_argument(
        '-t',
        '--tolerance_key',
        metavar='FLOAT',
        default=90.0,
        help='At a given position in the alignment, minimum proportion '
        'patterns with the key residue to report it in the consensus. '
        'Default = 90%%.'
    )
    group1.add_argument(
        '-b',
        '--tolerance_blocks',
        metavar='FLOAT',
        default=10.0,
        help='At a given block in the consensus, discard the largest and '
        'smallest values. Default = 10%%.'
    )
    group1.add_argument(
        '-o',
        '--output',
        metavar='STR',
        default=None,
        help='Identifier for output files.')
    group1.add_argument(
        '-h', '--help', action='help', help='Print this help page and exit.')
    group1.add_argument(
        '-V',
        '--version',
        action='version',
        version='Current version: KAPPA 1.1',
        help='Show program\'s version number and exit.')

    args = parser.parse_args()
    alignment_file_names = args.alignments
    key_residue = args.key_residue
    tolerance_key = args.tolerance_key
    tolerance_blocks = args.tolerance_blocks
    file_id = args.output

    # Check arguments

    errors = []

    for alignment_file_name in alignment_file_names:
        try:
            if not os.path.exists(alignment_file_name):
                raise ValueError
        except ValueError:
            errors.append('ERROR: -a: File ' + alignment_file_name +
                          ' does not exist.')

    try:
        if len(key_residue) != 1 and key_residue not in 'ACDEFGHIKLMNPQRSTVWY':
            raise ValueError
    except ValueError:
        errors.append(
            'ERROR: -k: Key residue must be one letter belonging to '
            'ACDEFGHIKLMNPQRSTVWY.'
        )

    try:
        if float(tolerance_key) < 0.0 or float(tolerance_key) > 100.0:
            raise ValueError
        else:
            tolerance_key = float(tolerance_key) / 100.0
    except ValueError:
        errors.append(
            'ERROR: -t: Min proportion of empty sequences must be a '
            'real number between 0.0 and 100.0'
        )

    try:
        if float(tolerance_blocks) < 0.0 or float(tolerance_blocks) > 50.0:
            raise ValueError
        else:
            tolerance_blocks = float(tolerance_blocks) / 100.0
    except ValueError:
        errors.append(
            'ERROR: -b: Min proportion of gaps must be a real number '
            'between 0.0 and 50.0'
        )

    start_time = datetime.datetime.now()
    if file_id is not None:
        try:
            if 'Patterns_' + file_id + '.txt' in os.listdir('.'):
                raise ValueError
        except ValueError:
            errors.append(
                'ERROR: -o: This output identifier is already used in '
                'present working directory.'
            )
    else:
        file_id = start_time.strftime('%y-%m-%d_%H-%M-%S')

    if errors != []:
        for error in errors:
            sys.stderr.write(error + '\n')
        sys.stderr.write('\n')
        sys.exit(1)

    # Lauch execution

    start_time = datetime.datetime.now().strftime('%y-%m-%d_%H-%M-%S')

    final_consensus = []

    for alignment_file_name in alignment_file_names:

        print_stdout(
            'Analyzing alignment from ' + alignment_file_name + '...',
            level=0,
            end='')

        sample = os.path.split(alignment_file_name)[-1]
        sample = sample[:sample.rfind('.')]

        alignment, nseq, length = import_alignment(alignment_file_name)
        alignment = check_key_residues(alignment, nseq, length, key_residue,
                                       tolerance_key)
        patterns, nblocks = extract_patterns(alignment, key_residue)
        consensus = make_consensus(patterns, key_residue, nblocks,
                                   tolerance_blocks)

        final_consensus.append([sample, consensus])

        print_stdout('Done.', level=1, end='\n')

    out_file = open('Patterns_' + file_id + '.txt', 'w')
    out_table = csv.writer(out_file, dialect='excel-tab')
    for row in final_consensus:
        out_table.writerow(row)
    out_file.close()

    print_stdout('Execution finished', level=0, end='\n')
